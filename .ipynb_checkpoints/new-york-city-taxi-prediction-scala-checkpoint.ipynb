{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.{DataFrame, types, functions}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel, feature, evaluation, regression, tuning}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val test = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"test.csv\")\n",
    "val train = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// feature engineering\n",
    "def create_features(df: DataFrame, train_set: Boolean = true): DataFrame = {\n",
    "   // converting strings to double\n",
    "  var columns = Array(\"trip_duration\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"passenger_count\") \n",
    "  var temp = df\n",
    "  // robust to a train or test set, without the fare amount column\n",
    "  for(column <- columns){\n",
    "    if(train_set || column != \"trip_duration\"){\n",
    "       temp = temp.withColumn(column, temp(column).cast(types.DoubleType))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // getting dow\n",
    "  temp.createOrReplaceTempView(\"train\")\n",
    "  var dow = \"SELECT *, DATE_FORMAT(TO_TIMESTAMP(SUBSTRING(pickup_datetime, 1, 19)), 'EEEE') AS dow FROM train\"\n",
    "  temp = spark.sql(dow)\n",
    "  \n",
    "  // converting day of week to one hot encoding\n",
    "  val features = temp.columns.filter(_.contains(\"dow\"))\n",
    "  val encodedFeatures = features.flatMap{ name =>\n",
    "    val stringIndexer = new feature.StringIndexer()\n",
    "      .setInputCol(name)\n",
    "      .setOutputCol(name + \"_index\")\n",
    "\n",
    "    val oneHotEncoder = new feature.OneHotEncoderEstimator()\n",
    "      .setInputCols(Array(name + \"_index\"))\n",
    "      .setOutputCols(Array(name + \"_vec\"))\n",
    "      .setDropLast(false)\n",
    "\n",
    "    Array(stringIndexer, oneHotEncoder)\n",
    "  }\n",
    "  val pipeline = new Pipeline().setStages(encodedFeatures)\n",
    "  val indexer_model = pipeline.fit(temp)\n",
    "  temp = indexer_model.transform(temp)\n",
    "  \n",
    "  // changing datetimes from strings to datetimes\n",
    "  temp = temp.withColumn(\"pickup_datetime\", functions.to_timestamp(temp(\"pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "  \n",
    "  // create columns for year, month, day, hour, minute\n",
    "  temp = temp.withColumn(\"year\", functions.year(temp(\"pickup_datetime\")))\n",
    "  temp = temp.withColumn(\"month\", functions.month(temp(\"pickup_datetime\")))\n",
    "  temp = temp.withColumn(\"day\", functions.dayofmonth(temp(\"pickup_datetime\")))\n",
    "  temp = temp.withColumn(\"hour\", functions.hour(temp(\"pickup_datetime\")))\n",
    "  temp = temp.withColumn(\"minute\", functions.minute(temp(\"pickup_datetime\")))\n",
    "  \n",
    "  // drop fares <= 0\n",
    "  if(train_set){\n",
    "      temp = temp.filter(temp(\"trip_duration\") > 0)\n",
    "  }\n",
    "  // drop nas\n",
    "  temp = temp.na.drop()\n",
    "  // renaming trip_duration to labels\n",
    "  if(train_set){\n",
    "      temp = temp.withColumn(\"label\", temp(\"trip_duration\"))\n",
    "  }\n",
    "  // dropping unecessary columns\n",
    "  val drop_columns = Array(\"key\", \"trip_duration\", \"pickup_datetime\", \"dow\", \"dow_index\")\n",
    "  for(drop <- drop_columns){\n",
    "    temp = temp.drop(drop)\n",
    "  }\n",
    "  \n",
    "  return temp\n",
    "}\n",
    "// creating engineered training data\n",
    "val training_data = create_features(train)\n",
    "val test_data = create_features(test, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// vector assembler\n",
    "val vec_assembler = new feature.VectorAssembler()\n",
    "  .setInputCols(Array(\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"passenger_count\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"dow_vec\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// pipeline\n",
    "val pipeline = new Pipeline()\n",
    "    .setStages(Array(vec_assembler))\n",
    "val piped_data = pipeline.fit(training_data).transform(training_data)\n",
    "\n",
    "// train test split\n",
    "val Array(trainingData, testData) = piped_data.randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "// evaluator\n",
    "val evaluator = new evaluation.RegressionEvaluator()\n",
    "    .setMetricName(\"rmse\")\n",
    "\n",
    "// specify model\n",
    "val dt = new regression.DecisionTreeRegressor()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setFeaturesCol(\"features\")\n",
    "\n",
    "// grid search\n",
    "val paramGrid = new tuning.ParamGridBuilder()\n",
    "  .addGrid(dt.maxDepth, Array(10))\n",
    "  .build()\n",
    "\n",
    "// cross validation\n",
    "val cv = new tuning.CrossValidator()\n",
    "  .setEstimator(dt)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  //.setNumFolds(1)\n",
    "\n",
    "// train model\n",
    "val models = cv.fit(trainingData)\n",
    "val best_model = models.bestModel\n",
    "\n",
    "// evaluate on the test set\n",
    "val predictions = best_model.transform(testData)\n",
    "val result = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// test predictions\n",
    "val test_piped_data = pipeline.fit(test_data).transform(test_data)\n",
    "val test_predictions = best_model.transform(test_piped_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
